% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/kappa.R
\name{kappa}
\alias{kappa}
\alias{kappa1}
\alias{kappa0}
\title{Cohen's Kappa,}
\usage{
kappa(obs, ref)

kappa1(obs, ref)

kappa0(obs, ref)
}
\arguments{
\item{obs}{numeric; observed accuracy}

\item{ref}{numeric; reference/expected accuracy}
}
\description{
Calculate Kohen's Kappa, an accuracy adjust for expectations
}
\details{
Like \href{imp()}{improvement}, \code{kappa} measures the improvement in a metric
(typically: \emph{accuracy}) but normalizes the improvement by the best possible
value, e.g. \code{accuracy == 1}.
`
Cohen's Kapps is calculated as:\preformatted{ ( obs - ref ) / ( 1 - ref )
}

It can be thought of as how much improvement has been achieved versus how much
can be achieved. Likewise \code{1-kappa} can be thought of as home much additional
improvements can be made. Cohen's Kappa assumes the best model is 1. For this
reason \code{kappa1} is an alias for \code{kappa}.

\code{kappa0} is similar to \code{kappa1} but assumes that best possible score is 0 and
not 1. This would be a
`
}
\examples{

 ref <- 0.95    # naive accuracy
 obs <- 0.98    # model accuracy

 kappa(0.98,0.95)
   
 kappa0(0.40, 0.50)    
   
}
\seealso{
\href{imp()}{imp(rovement)}
}
